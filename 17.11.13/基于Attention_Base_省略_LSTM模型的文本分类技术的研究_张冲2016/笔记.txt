ＷｏｒｄＥｍｂｅｄｄｉｎｇ
	将文本数据映射到一个低维度的实数向量，避免了高维度的输入导致ＬＳＴＭ模型产生维度灾难的问题

自然语言处理领域的深度学习模型
在词向量表示方面
	连续词袋模型（ＣＢＯＷ）和连续ｓｋｉｐ－ｇｒａｍ模型
在机器翻译方面
	ＣＤ－ＤＮＮ－ＨＭＭ模型，解决对齐的数据稀疏问题，同时利用上下文信息提高翻译效果
在情感分析方面
	卷积神经网络
在中文分词领域
	去噪自动编码神经网络结合文本窗口处理方法
	基于长短时记忆神经网络（ＬＳＴＭ）模型和双向长短时记忆神经网络（团－ＬＳＴＭ），
文本分类领域常见的深度学习模型有
	ＲＮＮ模型
	ＬＳＴＭ模型
	Ｂｉ－ＬＳＴＭ模型

ＬＳＴＭ模型：
遗忘口（Ｆｏ巧ｅｔＧａｔｅ）
输入口（ｈｐｕｔＧａｔｅ）
输出口（ＯｕｔｐｕｔＧａｔｅ）

ＷｏｒｄＥｍｂｅｄｄｉｎｇ

ｗｏｒｄ２ｖｅｃ模型:
	利用深度学习模型，训练出指定维度的词向量，这些词向量之间的相似度（通过词之间的距离来计算）表示了单词之间的相似度
	
	Ｓｋｉｐ－ｇ巧ｍ模型:
		利用中间词去计算周围词为词典中某一词的概率

	ＣＢＯＷ模型:
		利用上下文去计算当前词为词典中某一词的概率

	策略：
		一种是基于层次化的网络结构来训练
		另一种是基于抽样的方法来训练

Ｓｋｉｐ－ｇｒａｍ文本表示模型
	一种利用单词预测周围词的概率的模型

Ａｔｔｅｎｔｉｏｎ－ＢａｓｅｄＬＳＴＭ模型原理















